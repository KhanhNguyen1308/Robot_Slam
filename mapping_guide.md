# üó∫Ô∏è AUTONOMOUS LIBRARY MAPPING - V3.0

## T·ªïng quan

H·ªá th·ªëng **t·ª± ƒë·ªông kh√°m ph√° v√† v·∫Ω b·∫£n ƒë·ªì** m√¥i tr∆∞·ªùng trong nh√† (th∆∞ vi·ªán, ph√≤ng kh√°ch, vƒÉn ph√≤ng...) s·ª≠ d·ª•ng:
- **Frontier-based Exploration** - T·ª± ƒë·ªông t√¨m v√πng ch∆∞a kh√°m ph√°
- **Occupancy Grid Mapping** - X√¢y d·ª±ng b·∫£n ƒë·ªì 2D chi ti·∫øt
- **A* Path Planning** - L·∫≠p k·∫ø ho·∫°ch ƒë∆∞·ªùng ƒëi t·ªëi ∆∞u
- **Pure Pursuit Control** - ƒêi·ªÅu khi·ªÉn theo ƒë∆∞·ªùng ƒëi ƒë√£ l·∫≠p

## üéØ T√≠nh nƒÉng

### Autonomous Mapping
- ‚úÖ T·ª± ƒë·ªông kh√°m ph√° to√†n b·ªô ph√≤ng/th∆∞ vi·ªán
- ‚úÖ X√¢y d·ª±ng b·∫£n ƒë·ªì occupancy grid (5cm resolution)
- ‚úÖ Tr√°nh v·∫≠t c·∫£n trong qu√° tr√¨nh kh√°m ph√°
- ‚úÖ T·ª± ƒë·ªông t√¨m frontier (bi√™n gi·ªõi kh√°m ph√°)
- ‚úÖ Path planning v·ªõi A* algorithm
- ‚úÖ Smooth path following v·ªõi Pure Pursuit

### Map Visualization
- ‚úÖ Real-time map building
- ‚úÖ Robot position v√† orientation
- ‚úÖ Planned path visualization
- ‚úÖ Exploration progress tracking
- ‚úÖ Save/load map functionality

### Intelligent Exploration
- ‚úÖ Frontier clustering ƒë·ªÉ ch·ªçn m·ª•c ti√™u t·ªëi ∆∞u
- ‚úÖ Tr√°nh l·∫∑p l·∫°i v√πng ƒë√£ kh√°m ph√°
- ‚úÖ T·ª± ƒë·ªông detect khi ho√†n th√†nh
- ‚úÖ Obstacle inflation cho safety margin

## üì¶ Files m·ªõi

### Core Modules
1. **slam_mapping.py** (580 d√≤ng)
   - `OccupancyGrid` - 2D occupancy grid map
   - `FrontierExplorer` - Frontier-based exploration
   - Map save/load functionality

2. **path_planning.py** (450 d√≤ng)
   - `AStarPlanner` - A* path planning
   - `PurePursuitController` - Path following control
   - Obstacle inflation
   - Path smoothing

3. **library_mapper.py** (420 d√≤ng)
   - `LibraryMapper` - Main autonomous mapping system
   - `LibraryMapVisualizer` - Real-time visualization
   - State machine for mapping flow

4. **demo_mapping.py** (350 d√≤ng)
   - Full autonomous mapping demo
   - Manual exploration demo
   - Status monitoring

## üöÄ S·ª≠ d·ª•ng

### 1. Quick Start

```bash
# Run robot system
python3 main.py

# In another terminal, run mapping demo
python3 demo_mapping.py
```

### 2. Web Interface

```bash
# Truy c·∫≠p web interface
http://localhost:5000

# Xem b·∫£n ƒë·ªì real-time
http://localhost:5000/video/map

# Xem camera + obstacles
http://localhost:5000/video/obstacles
```

### 3. API Control

```python
import requests

# Start mapping
requests.post('http://localhost:5000/api/mapping', 
              json={'enable': True})

# Check status
status = requests.get('http://localhost:5000/api/mapping/status').json()
print(f"Progress: {status['exploration_progress']*100:.1f}%")

# Save map
requests.post('http://localhost:5000/api/mapping/save',
              json={'filename': 'my_library'})

# Stop mapping
requests.post('http://localhost:5000/api/mapping', 
              json={'enable': False})
```

### 4. Python API

```python
from library_mapper import LibraryMapper

# Create mapper
mapper = LibraryMapper(
    map_width=15.0,      # 15m x 15m
    map_height=15.0,
    resolution=0.05      # 5cm cells
)

# Start mapping
mapper.start_mapping()

# Update loop
while not mapper.explorer.exploration_complete:
    linear, angular = mapper.update(robot_pose, depth_map, camera_params)
    # Send velocity to robot
    
# Save result
mapper.save_map('library_map')
```

## üéÆ Mapping Demos

### Demo 1: Full Autonomous (5 ph√∫t)
```bash
python3 demo_mapping.py
# Ch·ªçn option 1

# Robot s·∫Ω:
# 1. T·ª± ƒë·ªông kh√°m ph√° to√†n b·ªô ph√≤ng
# 2. Tr√°nh v·∫≠t c·∫£n
# 3. X√¢y d·ª±ng b·∫£n ƒë·ªì
# 4. T·ª± ƒë·ªông d·ª´ng khi ho√†n th√†nh
```

### Demo 2: Extended Mapping (15 ph√∫t)
```bash
# Cho ph√≤ng l·ªõn ho·∫∑c th∆∞ vi·ªán
python3 demo_mapping.py
# Ch·ªçn option 2
```

### Demo 3: Manual Exploration
```bash
# B·∫°n ƒëi·ªÅu khi·ªÉn robot, h·ªá th·ªëng v·∫Ω b·∫£n ƒë·ªì
python3 demo_mapping.py
# Ch·ªçn option 3

# Sau ƒë√≥ ƒëi·ªÅu khi·ªÉn qua web interface
# Map s·∫Ω ƒë∆∞·ª£c build t·ª± ƒë·ªông khi robot di chuy·ªÉn
```

## üìä Mapping Algorithm

### Frontier-Based Exploration

```
1. UPDATE MAP from depth sensor
2. FIND FRONTIERS (boundary between known/unknown)
3. CLUSTER frontiers into groups
4. SELECT closest frontier cluster
5. PLAN PATH to frontier using A*
6. FOLLOW PATH using Pure Pursuit
7. REPEAT until no frontiers left
```

### Occupancy Grid

```
- Grid size: configurable (default 15m x 15m)
- Resolution: 5cm per cell (200x200 cells for 10m map)
- Values:
  - 0.0 = FREE space
  - 0.5 = UNKNOWN
  - 1.0 = OCCUPIED
```

### Path Planning

```
A* Algorithm:
- 8-connected grid
- Euclidean distance heuristic
- Obstacle inflation for safety
- Path smoothing via shortcutting
```

## üîß Configuration

### Map Parameters (main.py)

```python
config = {
    # Mapping
    'map_width': 15.0,           # meters
    'map_height': 15.0,          # meters
    'map_resolution': 0.05,      # 5cm cells
    'show_map_viz': False,       # Live OpenCV window
}
```

### Tuning Parameters

```python
# LibraryMapper
max_linear_speed = 0.25   # m/s (slow for safety)
max_angular_speed = 1.0   # rad/s

# Frontier Explorer
min_cluster_size = 15     # Minimum frontier cluster

# A* Planner
inflation_radius = 4      # Safety margin (20cm)

# Pure Pursuit
lookahead_distance = 0.5  # meters
```

## üìà Performance

### Typical Performance
- **Mapping speed**: ~2-3 m¬≤/minute
- **10m x 10m room**: ~30-40 minutes
- **Small library**: ~20-30 minutes
- **Resolution**: 5cm (accurate to bookshelf level)

### Optimization
```python
# Faster mapping (lower accuracy)
map_resolution = 0.1  # 10cm cells

# Slower mapping (higher accuracy)
map_resolution = 0.03  # 3cm cells

# Speed up movement
max_linear_speed = 0.4  # m/s
```

## üéØ Use Cases

### 1. Th∆∞ vi·ªán / Library
```python
# Large area, nhi·ªÅu bookshelves
mapper = LibraryMapper(
    map_width=20.0,
    map_height=15.0,
    resolution=0.05
)
```

### 2. Ph√≤ng kh√°ch / Living Room
```python
# Smaller area, furniture
mapper = LibraryMapper(
    map_width=8.0,
    map_height=8.0,
    resolution=0.03  # Higher detail
)
```

### 3. VƒÉn ph√≤ng / Office
```python
# Multiple rooms, corridors
mapper = LibraryMapper(
    map_width=25.0,
    map_height=20.0,
    resolution=0.05
)
```

## üóÇÔ∏è Map Files

### Saved Files
```
library_map_20260210_143022.png          # Map visualization
library_map_20260210_143022.npz          # Map data
library_map_20260210_143022_metadata.json # Mapping stats
```

### Map Data
```python
# Load map
import numpy as np
data = np.load('library_map.npz')

grid = data['grid']        # Occupancy grid
visited = data['visited']  # Visited cells
resolution = data['resolution']
width = data['width']
height = data['height']
```

### Metadata
```json
{
  "state": "COMPLETED",
  "exploration_progress": 0.87,
  "explored_cells": 34821,
  "total_cells": 40000,
  "elapsed_time": 1847.3,
  "distance_traveled": 45.7
}
```

## üîç Monitoring

### Real-time Status
```python
# Get mapping status
status = mapper.get_status()

print(f"State: {status['state']}")
print(f"Progress: {status['exploration_progress']*100:.1f}%")
print(f"Distance: {status['distance_traveled']:.1f}m")
print(f"Time: {status['elapsed_time']:.0f}s")
```

### Web Interface
- `/video/map` - Live map view
- `/api/mapping/status` - JSON status
- Main interface shows progress bar

## üêõ Troubleshooting

### Robot kh√¥ng di chuy·ªÉn
```bash
# Check motor enable
curl http://localhost:5000/api/status

# Check mapping state
curl http://localhost:5000/api/mapping/status
```

### Map kh√¥ng ch√≠nh x√°c
```bash
# Recalibrate camera
python3 calibrate_stereo.py --calibrate

# Check depth map
# View at /video/depth
```

### Exploration kh√¥ng complete
```python
# Adjust frontier detection
min_cluster_size = 10  # Lower threshold

# Or manually stop and save
mapper.stop_mapping()
mapper.save_map('partial_map')
```

### Robot stuck
```python
# Increase stuck detection threshold
max_stuck_count = 15  # From 10

# Or reduce safety margin
inflation_radius = 3  # From 4
```

## üéì Advanced Usage

### Custom Exploration Strategy
```python
class CustomExplorer(FrontierExplorer):
    def get_next_goal(self, robot_pose):
        # Your custom logic
        # E.g., prefer frontiers on the right
        pass
```

### Multi-Floor Mapping
```python
# Map floor 1
mapper_f1 = LibraryMapper()
mapper_f1.start_mapping()
# ... explore floor 1 ...
mapper_f1.save_map('floor1')

# Map floor 2
mapper_f2 = LibraryMapper()
# ... explore floor 2 ...
mapper_f2.save_map('floor2')
```

### Merge with SLAM
```python
# Use ORB-SLAM3 pose for more accurate mapping
slam_pose = slam.get_pose()  # 4x4 matrix
mapper.update(slam_pose, depth_map, camera_params)
```

## üìö References

### Algorithms
- **Frontier-based Exploration**: Yamauchi 1997
- **A* Path Planning**: Hart et al. 1968
- **Pure Pursuit**: Coulter 1992
- **Occupancy Grid Mapping**: Moravec & Elfes 1985

### Papers
- "A Frontier-Based Approach for Autonomous Exploration"
- "Occupancy Grid Mapping: An Empirical Evaluation"
- "Real-Time Path Planning for Mobile Robots"

## üöÄ Future Enhancements

- [ ] Multi-robot collaborative mapping
- [ ] 3D mapping (multi-floor)
- [ ] Semantic mapping (room labels)
- [ ] Loop closure detection
- [ ] Graph SLAM integration
- [ ] ROS compatibility

---

**Version**: 3.0  
**Feature**: Autonomous Library Mapping  
**Status**: Production Ready  
**Best for**: Indoor environments (libraries, offices, homes)