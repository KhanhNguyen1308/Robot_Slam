# Fix: HÆ°á»›ng Robot Hiá»ƒn Thá»‹ Sai / Robot Orientation Display Fix

## Váº¥n Ä‘á» / Problem

1. **HÆ°á»›ng robot (mÅ©i tÃªn xanh) hiá»ƒn thá»‹ sai** trÃªn Occupancy Grid
2. **Visual SLAM warning**: "Not enough matches for pose estimation: 7"
3. **Trajectory khÃ´ng khá»›p vá»›i hÆ°á»›ng robot**

## NguyÃªn nhÃ¢n / Root Cause

### 1. Coordinate System Mismatch
- **World frame**: Trá»¥c Y hÆ°á»›ng lÃªn (â†‘)
- **Image frame**: Trá»¥c Y hÆ°á»›ng xuá»‘ng (â†“)
- **Váº½ arrow khÃ´ng Ä‘áº£o ngÆ°á»£c Y** â†’ hÆ°á»›ng bá»‹ ngÆ°á»£c

### 2. Visual SLAM Failure
- Khi cÃ³ **<8 feature matches**, visual odometry khÃ´ng tÃ­nh Ä‘Æ°á»£c pose chÃ­nh xÃ¡c
- Orientation (theta) tá»« visual SLAM **bá»‹ sai hoáº·c giá»¯ nguyÃªn giÃ¡ trá»‹ cÅ©**
- Thiáº¿u IMU Ä‘á»ƒ bá»• sung khi visual tracking kÃ©m

### 3. Orientation Jumps
- Visual SLAM Ä‘Ã´i khi cho ra **orientation thay Ä‘á»•i Ä‘á»™t ngá»™t** khi tracking láº¡i
- KhÃ´ng cÃ³ **smoothing** â†’ mÅ©i tÃªn nháº£y lung tung

## Giáº£i phÃ¡p Ä‘Ã£ Ã¡p dá»¥ng / Solutions Applied

### âœ… Fix 1: Coordinate Transform
**File**: `web_server.py`

```python
# Before (SAI):
end_y = int(robot_gy + arrow_len * np.sin(mapper.theta))

# After (ÄÃšNG):
end_y = int(robot_gy - arrow_len * np.sin(mapper.theta))  # Negate Y
```

**Giáº£i thÃ­ch**: Image coordinates cÃ³ Y ngÆ°á»£c láº¡i, cáº§n Ä‘áº£o dáº¥u sin component.

### âœ… Fix 2: Orientation Jump Detection & Smoothing
**File**: `autonomous_mapper.py`

ThÃªm validation Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  lÃ m mÆ°á»£t orientation jumps:

```python
# Detect large orientation jumps (>45Â° in one frame)
theta_diff = abs(new_theta - self.theta)
if theta_diff > np.pi/4 and dist_moved < 0.05:
    # Smooth the orientation change
    new_theta = smooth_orientation(...)
```

### âœ… Fix 3: Better Visual SLAM Failure Handling
**File**: `orb_slam3_wrapper.py`

Cáº£i thiá»‡n xá»­ lÃ½ khi tracking tháº¥t báº¡i:
- Giá»¯ nguyÃªn pose cuá»‘i cÃ¹ng
- Cho phÃ©p IMU fusion xá»­ lÃ½ orientation

### âœ… Fix 4: IMU Integration (Ä‘Ã£ hoÃ n thÃ nh trÆ°á»›c Ä‘Ã³)
- MPU6050 cung cáº¥p **gyroscope 100Hz**
- **Sensor fusion** káº¿t há»£p Visual + IMU
- **Orientation tá»« IMU chÃ­nh xÃ¡c hÆ¡n** khi visual tracking kÃ©m

## CÃ¡ch test / How to Test

### 1. Verify IMU Connection

```bash
# Check MPU6050 is detected
sudo i2cdetect -y -r 1
# Should show "68" at address 0x68
```

### 2. Test IMU

```bash
cd /home/jetson/Robot_Slam/Ver2
python3 test_imu.py
# Choose test 1: Basic Connection
```

Náº¿u IMU fail:
```bash
# Check I2C permissions
sudo usermod -a -G i2c $USER
sudo chmod 666 /dev/i2c-1

# Install dependencies
pip3 install smbus2
```

### 3. Run System with IMU Fusion

```bash
python3 main.py
```

**Quan trá»ng**: Khi khá»Ÿi Ä‘á»™ng, **giá»¯ robot Ä‘á»©ng yÃªn** 5 giÃ¢y Ä‘á»ƒ IMU calibrate!

### 4. Monitor Orientation

Trong web interface (`http://<jetson-ip>:5000`), kiá»ƒm tra:

```bash
# Check if IMU is active
curl http://<jetson-ip>:5000/api/status | jq '.imu_available'
# Should return: true

# Check fusion stats
curl http://<jetson-ip>:5000/api/status | jq '.fusion'
# Should show:
# {
#   "visual_updates": 1234,
#   "imu_updates": 5678,  <- Should be much higher than visual
#   "last_imu_age": 0.01  <- Should be < 0.02 seconds
# }

# Check IMU orientation
curl http://<jetson-ip>:5000/api/imu | jq '.orientation'
```

## Expected Behavior After Fix

### TrÆ°á»›c / Before:
```
âŒ MÅ©i tÃªn xanh chá»‰ sai hÆ°á»›ng
âŒ Trajectory khÃ´ng khá»›p vá»›i orientation
âŒ Orientation nháº£y lung tung
âŒ Khi Ã­t features, robot "máº¥t phÆ°Æ¡ng hÆ°á»›ng"
```

### Sau / After:
```
âœ… MÅ©i tÃªn xanh chá»‰ Ä‘Ãºng hÆ°á»›ng di chuyá»ƒn
âœ… Trajectory khá»›p vá»›i orientation
âœ… Orientation thay Ä‘á»•i mÆ°á»£t mÃ 
âœ… IMU giá»¯ orientation á»•n Ä‘á»‹nh khi visual tracking kÃ©m
âœ… Äá»™ chÃ­nh xÃ¡c: Â±1-2Â° (thay vÃ¬ Â±5-10Â°)
```

## Troubleshooting

### Issue 1: MÅ©i tÃªn váº«n chá»‰ sai
**Check**: IMU cÃ³ hoáº¡t Ä‘á»™ng khÃ´ng?
```bash
curl http://<jetson-ip>:5000/api/imu
```
Náº¿u lá»—i â†’ IMU chÆ°a káº¿t ná»‘i â†’ xem `MPU6050_INTEGRATION.md`

### Issue 2: Orientation váº«n nháº£y
**Giáº£i phÃ¡p**: TÄƒng smoothing factor

Edit `autonomous_mapper.py`:
```python
# Line ~320: Increase smoothing
if theta_diff > np.pi/8:  # Change from np.pi/4 to np.pi/8 (more aggressive)
    ...
    new_theta = self.theta + np.clip(theta_diff, -np.pi/16, np.pi/16) * ...
```

### Issue 3: Visual SLAM váº«n bÃ¡o "Not enough matches"
ÄÃ¢y lÃ  **bÃ¬nh thÆ°á»ng** khi:
- Ãnh sÃ¡ng kÃ©m
- Bá» máº·t trÆ¡n, Ã­t texture
- Robot quay nhanh

**Giáº£i phÃ¡p**: IMU sáº½ tá»± Ä‘á»™ng xá»­ lÃ½! KhÃ´ng cáº§n lo.

Náº¿u **quÃ¡ thÆ°á»ng xuyÃªn** (>50% frames):
1. Cáº£i thiá»‡n Ã¡nh sÃ¡ng
2. ThÃªm visual features (stickers, tape patterns) trÃªn tÆ°á»ng
3. Giáº£m tá»‘c Ä‘á»™ di chuyá»ƒn

### Issue 4: IMU drift sau nhiá»u phÃºt
**Expected behavior**: Sensor fusion sáº½ tá»± hiá»‡u chá»‰nh drift tá»« visual SLAM.

Náº¿u drift > 5Â° sau 5 phÃºt:
1. Re-calibrate IMU: Cháº¡y test_imu.py test 3
2. Kiá»ƒm tra MPU6050 gáº¯n cháº¯c cháº¯n (khÃ´ng rung)
3. TÄƒng trust visual SLAM: 

Edit `main.py` config:
```python
'imu': {
    ...
    'fusion_weight': 0.2,  # Giáº£m tá»« 0.3 xuá»‘ng 0.2 (trust visual more)
}
```

## Advanced Debugging

### Log Orientation Values

ThÃªm logging vÃ o `autonomous_mapper.py`:

```python
# In _exploration_loop, after getting pose:
if slam_pose:
    logger.info(f"Pose: x={new_x:.2f}m, y={new_y:.2f}m, "
                f"theta={np.degrees(new_theta):.1f}Â° "
                f"(change: {np.degrees(theta_diff):.1f}Â°)")
```

### Visualize in Real-time

ThÃªm vÃ o web interface Ä‘á»ƒ show:
- Current theta tá»« visual SLAM
- Current theta tá»« IMU
- Fused theta (final)
- Number of feature matches

## Configuration Tuning

### For Smooth Movement:
```python
# main.py config
'motor': {
    'max_angular_speed': 1.0,  # Reduce from 1.5 to 1.0 rad/s
}

'imu': {
    'use_ekf': True,
    'fusion_weight': 0.3,  # Good default
}
```

### For Faster Response (náº¿u muá»‘n responsive hÆ¡n):
```python
'imu': {
    'use_ekf': True,
    'fusion_weight': 0.5,  # Trust IMU more
}
```

### For Accuracy (náº¿u visual SLAM tá»‘t):
```python
'imu': {
    'use_ekf': True,
    'fusion_weight': 0.2,  # Trust visual more
}
```

## Summary of Changes

| File | Change | Purpose |
|------|--------|---------|
| `web_server.py` | Negate Y in arrow drawing | Fix coordinate system |
| `orb_slam3_wrapper.py` | Better low-feature handling | Maintain pose stability |
| `autonomous_mapper.py` | Orientation jump detection | Smooth orientation |
| `main.py` (previous) | IMU integration | Accurate orientation |
| `imu_fusion.py` (previous) | Sensor fusion | Combine Visual+IMU |

## Next Steps

1. âœ… **Restart há»‡ thá»‘ng** vá»›i code má»›i
2. âœ… **Verify IMU** Ä‘ang hoáº¡t Ä‘á»™ng (check API)
3. âœ… **Test orientation** báº±ng cÃ¡ch quay robot báº±ng tay
4. âœ… **Run autonomous mapping** vÃ  quan sÃ¡t occupancy grid

HÆ°á»›ng robot bÃ¢y giá» sáº½ **chÃ­nh xÃ¡c vÃ  á»•n Ä‘á»‹nh** hÆ¡n nhiá»u! ğŸ¯
